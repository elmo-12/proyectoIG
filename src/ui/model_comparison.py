"""
Componente UI para comparaci√≥n de modelos
"""
import streamlit as st
import pandas as pd
import plotly.express as px
import os
import time
import base64
from typing import Dict, List

from ..models.model_manager import model_manager
from ..config.settings import get_model_dir
from ..visualization.charts import chart_generator

class ModelComparisonUI:
    """Interfaz de usuario para comparaci√≥n de modelos"""
    
    def __init__(self):
        self.model_manager = model_manager
        self.chart_generator = chart_generator
        
    def render(self):
        """Renderizar interfaz de comparaci√≥n de modelos"""
        st.header("üìä Comparaci√≥n de Modelos de Diagn√≥stico")
        
        # Verificar modelos disponibles
        available_models = self._get_available_models()
        
        if not available_models:
            self._render_no_models_message()
            return
        
        # Mostrar informaci√≥n de modelos disponibles
        st.success(f"‚úÖ Se encontraron {len(available_models)} modelo(s) para comparar")
        
        # Recopilar datos de los modelos
        models_data = self._collect_models_data(available_models)
        
        if not models_data['Modelo']:
            st.error("‚ùå No se pudieron cargar los datos de los modelos")
            return
        
        # Crear DataFrame
        df = pd.DataFrame(models_data)
        
        # Renderizar m√©tricas de resumen
        self._render_summary_metrics(df)
        
        # Renderizar tabla detallada
        self._render_detailed_table(df)
        
        # Renderizar visualizaciones
        self._render_visualizations(df)
        
        # Renderizar recomendaciones
        self._render_recommendations(df)
        
        # Renderizar opci√≥n de exportar
        self._render_export_option(df)
    
    def _get_available_models(self) -> List[str]:
        """Obtener lista de modelos disponibles"""
        available_models = []
        model_files = [
            "best_sugarcane_modelV1.keras",
            "best_sugarcane_modelV2.keras",
            "best_sugarcane_modelV3.keras"
        ]
        
        # Incluir cualquier otro modelo .keras en la carpeta
        model_dir = get_model_dir()
        try:
            if os.path.exists(model_dir):
                additional_models = [f for f in os.listdir(model_dir) if f.endswith('.keras')]
                model_files = list(set(model_files + additional_models))
        except:
            pass
        
        # Verificar cu√°les existen
        for model_file in model_files:
            model_path = os.path.join(model_dir, model_file)
            if os.path.exists(model_path):
                available_models.append(model_file)
        
        return available_models
    
    def _render_no_models_message(self):
        """Renderizar mensaje cuando no hay modelos"""
        st.warning("‚ö†Ô∏è No se encontraron modelos para comparar")
        st.info("üí° Carga modelos en la pesta√±a de Configuraci√≥n para poder compararlos")
        
        with st.expander("üîß Crear Modelos de Ejemplo", expanded=False):
            st.markdown("""
            Para crear modelos de ejemplo para comparaci√≥n, puedes:
            
            1. **Usar el modelo actual**: El modelo cargado en la pesta√±a de Configuraci√≥n
            2. **Crear modelos de demostraci√≥n**: Ejecutar scripts de entrenamiento
            3. **Cargar modelos externos**: Subir archivos .keras desde tu computadora
            
            Los modelos se comparar√°n autom√°ticamente cuando est√©n disponibles.
            """)
    
    def _collect_models_data(self, available_models: List[str]) -> Dict[str, List]:
        """Recopilar datos de los modelos"""
        models_data = {
            'Modelo': [],
            'Precisi√≥n': [],
            'P√©rdida': [],
            'F1-Score Promedio': [],
            'Tama√±o (MB)': [],
            'Fecha Creaci√≥n': [],
            'Estado': []
        }
        
        for model_file in available_models:
            model_path = os.path.join(get_model_dir(), model_file)
            model_name = model_file.replace('.keras', '')
            models_data['Modelo'].append(model_name)
            
            # Cargar informaci√≥n estad√≠stica
            model_info = self.model_manager.load_model_info(model_file)
            if model_info:
                models_data['Precisi√≥n'].append(model_info['test_accuracy'])
                models_data['P√©rdida'].append(model_info['test_loss'])
                
                # Extraer F1-Score
                f1_score = self._extract_f1_score(model_info['full_report'])
                models_data['F1-Score Promedio'].append(f1_score)
                
                # Determinar estado
                if model_info['test_accuracy'] >= 0.7:
                    models_data['Estado'].append('‚úÖ Excelente')
                elif model_info['test_accuracy'] >= 0.5:
                    models_data['Estado'].append('‚ö†Ô∏è Aceptable')
                else:
                    models_data['Estado'].append('‚ùå Necesita mejoras')
            else:
                models_data['Precisi√≥n'].append(0.0)
                models_data['P√©rdida'].append(0.0)
                models_data['F1-Score Promedio'].append(0.0)
                models_data['Estado'].append('‚ùì Sin informaci√≥n')
            
            # Obtener tama√±o y fecha
            try:
                size_mb = os.path.getsize(model_path) / (1024 * 1024)
                models_data['Tama√±o (MB)'].append(round(size_mb, 2))
                
                creation_time = os.path.getctime(model_path)
                creation_date = time.strftime('%Y-%m-%d', time.localtime(creation_time))
                models_data['Fecha Creaci√≥n'].append(creation_date)
            except:
                models_data['Tama√±o (MB)'].append(0.0)
                models_data['Fecha Creaci√≥n'].append('N/A')
        
        return models_data
    
    def _extract_f1_score(self, report: str) -> float:
        """Extraer F1-Score del reporte"""
        try:
            lines = report.split('\n')
            for line in lines:
                if 'macro avg' in line and 'f1-score' in line:
                    parts = line.split()
                    return float(parts[3])
            return 0.0
        except:
            return 0.0
    
    def _render_summary_metrics(self, df: pd.DataFrame):
        """Renderizar m√©tricas de resumen"""
        st.subheader("üìà Resumen de M√©tricas")
        
        col1, col2, col3, col4 = st.columns(4)
        
        valid_precision = df[df['Precisi√≥n'] > 0]['Precisi√≥n']
        valid_f1 = df[df['F1-Score Promedio'] > 0]['F1-Score Promedio']
        
        with col1:
            if len(valid_precision) > 0:
                st.metric("Mejor Precisi√≥n", f"{valid_precision.max():.2%}")
            else:
                st.metric("Mejor Precisi√≥n", "N/A")
                
        with col2:
            if len(valid_precision) > 0:
                st.metric("Promedio Precisi√≥n", f"{valid_precision.mean():.2%}")
            else:
                st.metric("Promedio Precisi√≥n", "N/A")
                
        with col3:
            if len(valid_f1) > 0:
                st.metric("Mejor F1-Score", f"{valid_f1.max():.3f}")
            else:
                st.metric("Mejor F1-Score", "N/A")
                
        with col4:
            st.metric("Tama√±o Total", f"{df['Tama√±o (MB)'].sum():.1f} MB")
    
    def _render_detailed_table(self, df: pd.DataFrame):
        """Renderizar tabla detallada"""
        st.subheader("üìä Tabla Detallada de M√©tricas")
        
        # Formatear datos para mostrar
        display_df = df.copy()
        display_df['Precisi√≥n'] = display_df['Precisi√≥n'].apply(lambda x: f"{x:.2%}" if x > 0 else "N/A")
        display_df['P√©rdida'] = display_df['P√©rdida'].apply(lambda x: f"{x:.4f}" if x > 0 else "N/A")
        display_df['F1-Score Promedio'] = display_df['F1-Score Promedio'].apply(lambda x: f"{x:.3f}" if x > 0 else "N/A")
        
        st.dataframe(display_df, use_container_width=True)
    
    def _render_visualizations(self, df: pd.DataFrame):
        """Renderizar visualizaciones"""
        st.subheader("üìà Visualizaciones")
        
        # Filtrar modelos con datos v√°lidos
        valid_models = df[df['Precisi√≥n'] > 0]
        
        if len(valid_models) == 0:
            st.warning("‚ö†Ô∏è No hay datos suficientes para mostrar gr√°ficos")
            return
        
        # Gr√°ficos de barras
        col1, col2 = st.columns(2)
        
        with col1:
            fig1 = px.bar(
                valid_models, 
                x='Modelo', 
                y='Precisi√≥n',
                title='Precisi√≥n por Modelo',
                color='Precisi√≥n',
                color_continuous_scale='viridis'
            )
            fig1.update_traces(texttemplate='%{y:.1%}', textposition='outside')
            fig1.update_layout(
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font=dict(color='white'),
                yaxis=dict(tickformat='.0%')
            )
            st.plotly_chart(fig1, use_container_width=True)
        
        with col2:
            fig2 = px.bar(
                valid_models, 
                x='Modelo', 
                y='F1-Score Promedio',
                title='F1-Score Promedio por Modelo',
                color='F1-Score Promedio',
                color_continuous_scale='plasma'
            )
            fig2.update_traces(texttemplate='%{y:.3f}', textposition='outside')
            fig2.update_layout(
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font=dict(color='white')
            )
            st.plotly_chart(fig2, use_container_width=True)
        
        # Gr√°fico de dispersi√≥n
        if len(valid_models) > 1:
            st.subheader("üìâ An√°lisis de P√©rdida vs Precisi√≥n")
            fig3 = px.scatter(
                valid_models, 
                x='P√©rdida', 
                y='Precisi√≥n',
                size='Tama√±o (MB)', 
                hover_name='Modelo',
                title='Relaci√≥n entre P√©rdida y Precisi√≥n',
                color='F1-Score Promedio',
                color_continuous_scale='RdYlGn'
            )
            fig3.update_layout(
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font=dict(color='white')
            )
            st.plotly_chart(fig3, use_container_width=True)
        
        # Gr√°fico de tama√±os
        if len(df) > 1:
            st.subheader("üì¶ Comparaci√≥n de Tama√±os")
            fig4 = px.pie(
                df, 
                values='Tama√±o (MB)', 
                names='Modelo',
                title='Distribuci√≥n del Tama√±o de Modelos'
            )
            fig4.update_layout(
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font=dict(color='white')
            )
            st.plotly_chart(fig4, use_container_width=True)
    
    def _render_recommendations(self, df: pd.DataFrame):
        """Renderizar recomendaciones"""
        st.subheader("üí° Recomendaciones")
        
        valid_models = df[df['Precisi√≥n'] > 0]
        
        if len(valid_models) == 0:
            st.info("No hay suficientes datos para generar recomendaciones")
            return
        
        # Mejores modelos
        best_model = valid_models.loc[valid_models['Precisi√≥n'].idxmax(), 'Modelo']
        best_f1_model = valid_models.loc[valid_models['F1-Score Promedio'].idxmax(), 'Modelo']
        smallest_model = df.loc[df['Tama√±o (MB)'].idxmin(), 'Modelo']
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.info(f"üéØ **Mejor Precisi√≥n**: {best_model}")
            
        with col2:
            st.info(f"‚öñÔ∏è **Mejor F1-Score**: {best_f1_model}")
            
        with col3:
            st.info(f"üíæ **M√°s Peque√±o**: {smallest_model}")
        
        # An√°lisis del mejor modelo
        st.subheader("üèÜ An√°lisis del Mejor Modelo")
        best_model_info = self.model_manager.load_model_info(best_model + '.keras')
        
        if best_model_info:
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**Estad√≠sticas Principales:**")
                st.markdown(f"- Precisi√≥n: {best_model_info['test_accuracy']:.2%}")
                st.markdown(f"- P√©rdida: {best_model_info['test_loss']:.4f}")
                
            with col2:
                st.markdown("**Reporte Detallado:**")
                with st.expander("Ver reporte completo"):
                    st.text(best_model_info['full_report'])
        
        # Matrices de confusi√≥n
        self._render_confusion_matrices(valid_models)
    
    def _render_confusion_matrices(self, valid_models: pd.DataFrame):
        """Renderizar matrices de confusi√≥n"""
        st.subheader("üìä Matrices de Confusi√≥n")
        
        matrices_cols = st.columns(min(3, len(valid_models)))
        
        for i, (_, model_row) in enumerate(valid_models.iterrows()):
            if i >= 3:  # Mostrar m√°ximo 3 matrices
                break
                
            model_name = model_row['Modelo']
            confusion_path = self.model_manager.get_confusion_matrix_path(model_name + '.keras')
            
            if confusion_path and os.path.exists(confusion_path):
                with matrices_cols[i]:
                    st.markdown(f"**{model_name}**")
                    st.image(confusion_path, use_column_width=True)
    
    def _render_export_option(self, df: pd.DataFrame):
        """Renderizar opci√≥n de exportar"""
        st.subheader("üì§ Exportar Comparaci√≥n")
        
        if st.button("üìä Exportar Datos de Comparaci√≥n", use_container_width=True):
            # Formatear datos para exportar
            export_df = df.copy()
            export_df['Precisi√≥n'] = export_df['Precisi√≥n'].apply(lambda x: f"{x:.2%}" if x > 0 else "N/A")
            export_df['P√©rdida'] = export_df['P√©rdida'].apply(lambda x: f"{x:.4f}" if x > 0 else "N/A")
            export_df['F1-Score Promedio'] = export_df['F1-Score Promedio'].apply(lambda x: f"{x:.3f}" if x > 0 else "N/A")
            
            # Crear CSV
            csv = export_df.to_csv(index=False)
            b64 = base64.b64encode(csv.encode()).decode()
            href = f'<a href="data:file/csv;base64,{b64}" download="comparacion_modelos.csv">‚¨áÔ∏è Descargar CSV</a>'
            st.markdown(href, unsafe_allow_html=True)
            st.success("‚úÖ Datos exportados exitosamente") 